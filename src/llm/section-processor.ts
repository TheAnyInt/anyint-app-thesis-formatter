import { Logger } from '@nestjs/common';
import { ContentChunk } from './content-splitter';
import { ThesisData, Section, ThesisMetadata } from '../thesis/dto/thesis-data.dto';

const logger = new Logger('SectionProcessor');

/**
 * Result from processing a single chunk
 */
export interface ChunkProcessingResult {
  success: boolean;
  chunkIndex: number;
  data?: Partial<ThesisData>;
  error?: string;
  retryCount: number;
}

/**
 * Build the prompt for processing a single content chunk
 */
export function buildChunkPrompt(chunk: ContentChunk, hasFigureMarkers: boolean, figureIdList: string): string {
  const isFirstChunk = chunk.chunkIndex === 0;
  const hasOnlySections = chunk.sections.length > 0 && !chunk.includesAbstract && !chunk.includesReferences && !chunk.includesAcknowledgements;

  let contextInfo = '';
  if (chunk.totalChunks > 1) {
    contextInfo = `\n**æ³¨æ„ï¼šè¿™æ˜¯æ–‡æ¡£çš„ç¬¬ ${chunk.chunkIndex + 1}/${chunk.totalChunks} éƒ¨åˆ†ã€‚**\n`;
    if (!isFirstChunk) {
      contextInfo += '- ä¸éœ€è¦å†æ¬¡æå– metadataï¼Œè¿”å›ç©ºå¯¹è±¡å³å¯\n';
    }
  }

  const figureInstructions = hasFigureMarkers
    ? `
**å›¾ç‰‡å¤„ç†è¯´æ˜ï¼š**
æ–‡æœ¬ä¸­å¯èƒ½åŒ…å«å›¾ç‰‡æ ‡è®°: ${figureIdList}
æ¯ä¸ª [FIGURE:xxxX] æ ‡è®°ï¼ˆå¦‚ [FIGURE:docximg1]ï¼‰è¡¨ç¤ºè¯¥ä½ç½®æœ‰ä¸€å¼ å›¾ç‰‡ã€‚
**é‡è¦ï¼šåªå¤„ç†ä¸Šè¿°åˆ—å‡ºçš„å›¾ç‰‡IDï¼Œä¸è¦åˆ›å»ºå…¶ä»–å›¾ç‰‡å¼•ç”¨ï¼å¿…é¡»ä½¿ç”¨åŸå§‹çš„å›¾ç‰‡IDï¼**

è¯·åœ¨å¯¹åº”ç« èŠ‚çš„ content ä¸­å°†è¿™äº›æ ‡è®°è½¬æ¢ä¸º LaTeX æ ¼å¼ï¼ˆä¿ç•™åŸå§‹å›¾ç‰‡IDï¼‰ï¼š

ä¾‹å¦‚ [FIGURE:docximg1] åº”è½¬æ¢ä¸ºï¼š
\\\\begin{figure}[H]
    \\\\centering
    \\\\includegraphics[width=0.8\\\\textwidth]{docximg1.png}
    \\\\caption{æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­çš„å›¾ç‰‡æè¿°}
    \\\\label{fig:docximg1}
\\\\end{figure}

æ³¨æ„ï¼š
- åªèƒ½ä½¿ç”¨ä»¥ä¸‹å›¾ç‰‡ID: ${figureIdList}
- å¿…é¡»ä¿ç•™åŸå§‹çš„å›¾ç‰‡IDï¼ˆå¦‚ docximg1, pdfimg2 ç­‰ï¼‰ï¼Œä¸è¦ä¿®æ”¹ä¸ºå…¶ä»–åç§°
- ä¸è¦åˆ›å»ºä»»ä½•ä¸åœ¨ä¸Šè¿°åˆ—è¡¨ä¸­çš„å›¾ç‰‡å¼•ç”¨
- æ ¹æ®å›¾ç‰‡å‰åçš„æ–‡æœ¬å†…å®¹ï¼Œä¸ºæ¯å¼ å›¾ç‰‡ç”Ÿæˆåˆé€‚çš„ä¸­æ–‡æ ‡é¢˜ä½œä¸º caption
- ä¿æŒå›¾ç‰‡åœ¨åŸæ–‡ä¸­çš„ç›¸å¯¹ä½ç½®
`
    : '';

  // Build content to process
  let contentToProcess = '';

  if (chunk.includesAbstract && chunk.abstractContent) {
    contentToProcess += `ã€æ‘˜è¦éƒ¨åˆ†ã€‘\n${chunk.abstractContent}\n\n`;
  }

  for (const section of chunk.sections) {
    contentToProcess += `ã€${section.level === 1 ? 'ç« èŠ‚' : section.level === 2 ? 'å°èŠ‚' : 'å­èŠ‚'}ï¼š${section.title}ã€‘\n${section.content}\n\n`;
  }

  if (chunk.includesAcknowledgements && chunk.acknowledgementsContent) {
    contentToProcess += `ã€è‡´è°¢éƒ¨åˆ†ã€‘\n${chunk.acknowledgementsContent}\n\n`;
  }

  if (chunk.includesReferences && chunk.referencesContent) {
    contentToProcess += `ã€å‚è€ƒæ–‡çŒ®éƒ¨åˆ†ã€‘\n${chunk.referencesContent}\n\n`;
  }

  // Determine which fields to request
  const metadataInstruction = isFirstChunk
    ? `"metadata": {
    "title": "è®ºæ–‡æ ‡é¢˜",
    "title_en": "è‹±æ–‡æ ‡é¢˜ï¼ˆå¦‚æœ‰ï¼‰",
    "author_name": "ä½œè€…å§“å",
    "student_id": "å­¦å·ï¼ˆå¦‚æœ‰ï¼‰",
    "school": "å­¦é™¢/é™¢ç³»",
    "major": "ä¸“ä¸š",
    "supervisor": "æŒ‡å¯¼æ•™å¸ˆ",
    "date": "æ—¥æœŸ"
  }`
    : `"metadata": {}`;

  const abstractInstruction = chunk.includesAbstract
    ? `"abstract": "ä¸­æ–‡æ‘˜è¦å†…å®¹",
  "abstract_en": "è‹±æ–‡æ‘˜è¦å†…å®¹ï¼ˆå¦‚æœ‰ï¼‰",
  "keywords": "å…³é”®è¯1ã€å…³é”®è¯2ã€å…³é”®è¯3",
  "keywords_en": "keyword1, keyword2, keyword3",`
    : '';

  const sectionsInstruction = hasOnlySections || chunk.sections.length > 0
    ? `"sections": [
    {"title": "ç« èŠ‚æ ‡é¢˜", "content": "ç« èŠ‚å†…å®¹...", "level": 1},
    {"title": "å­èŠ‚æ ‡é¢˜", "content": "å­èŠ‚å†…å®¹...", "level": 2}
  ],`
    : `"sections": [],`;

  const referencesInstruction = chunk.includesReferences ? `"references": "å‚è€ƒæ–‡çŒ®åˆ—è¡¨",` : '';
  const ackInstruction = chunk.includesAcknowledgements ? `"acknowledgements": "è‡´è°¢å†…å®¹",` : '';

  return `è¯·ä»ä»¥ä¸‹è®ºæ–‡å†…å®¹ç‰‡æ®µä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚**æŒ‰åŸæ–‡å®é™…ç»“æ„æå–ï¼Œä¸è¦é¢„è®¾æˆ–å¼ºåˆ¶å¥—ç”¨å›ºå®šçš„ç« èŠ‚åç§°ã€‚**
${contextInfo}
è¾“å‡º JSON æ ¼å¼ï¼š

{
  ${metadataInstruction},
  ${abstractInstruction}
  ${sectionsInstruction}
  ${referencesInstruction}
  ${ackInstruction}
}

**é‡è¦è¯´æ˜ï¼š**
1. sections æ•°ç»„åŒ…å«è®ºæ–‡çš„æ­£æ–‡ç« èŠ‚ï¼ŒæŒ‰åŸæ–‡é¡ºåºæ’åˆ—
2. level: 1 è¡¨ç¤ºä¸€çº§æ ‡é¢˜ï¼ˆç« ï¼‰ï¼Œ2 è¡¨ç¤ºäºŒçº§æ ‡é¢˜ï¼ˆèŠ‚ï¼‰ï¼Œ3 è¡¨ç¤ºä¸‰çº§æ ‡é¢˜
3. **ç« èŠ‚æ ‡é¢˜åªä¿ç•™çº¯æ–‡å­—å†…å®¹ï¼Œå»æ‰ç¼–å·å‰ç¼€**ï¼š
   - "ç¬¬ä¸€ç«  ç»ªè®º" â†’ title: "ç»ªè®º"
   - "1.1 ç ”ç©¶èƒŒæ™¯" â†’ title: "ç ”ç©¶èƒŒæ™¯"
   - ç¼–å·ä¼šç”± LaTeX æ¨¡æ¿è‡ªåŠ¨ç”Ÿæˆ
4. å¦‚æœæŸä¸ªå­—æ®µåœ¨å†…å®¹ä¸­ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸² "" æˆ–ç©ºæ•°ç»„ []
5. ä¿æŒå­¦æœ¯è¯­è¨€çš„ä¸¥è°¨æ€§

**å…¬å¼å¤„ç†ï¼ˆæé‡è¦ï¼‰ï¼š**
- PDFæå–çš„å…¬å¼å¯èƒ½è¢«åˆ†æˆå¤šè¡Œæˆ–å¤šä¸ªç‰‡æ®µï¼ŒåŒ…å«Unicodeæ•°å­¦ç¬¦å·
- [FORMULA: ... :END_FORMULA] æ ‡è®°è¡¨ç¤ºå…¬å¼ç‰‡æ®µï¼Œå¯èƒ½éœ€è¦**åˆå¹¶ç›¸é‚»ç‰‡æ®µ**
- å¸¸è§æ¨¡å¼ï¼ˆéœ€è¦è¯†åˆ«å¹¶è½¬æ¢ï¼‰ï¼š
  - åˆ†æ•£çš„æ±‚å’Œå…¬å¼å¦‚ "ğ‘\\nâˆ‘\\nğ¿= âˆ’\\nğ‘–=1\\nğ‘¦ğ‘–log(ğ‘ğ‘–)" â†’ $$L = -\\sum_{i=1}^{N} y_i \\log(p_i)$$
  - å¸¦è¯´æ˜çš„å…¬å¼å¦‚ "å…¶ä¸­ï¼Œğ‘¦ğ‘–ä¸ºçœŸå®æ ‡ç­¾" â†’ å…¶ä¸­ï¼Œ$y_i$ä¸ºçœŸå®æ ‡ç­¾
- **å¿…é¡»å°†æ‰€æœ‰å…¬å¼è½¬æ¢ä¸ºæ ‡å‡†LaTeXæ ¼å¼**ï¼š
  - ç‹¬ç«‹å…¬å¼ç”¨ $$...$$ï¼Œè¡Œå†…å…¬å¼ç”¨ $...$
- å¸¸è§è½¬æ¢ï¼šğ›¼â†’\\alpha, ğ›½â†’\\beta, âˆ‘â†’\\sum, âˆâ†’\\prod, âˆ«â†’\\int, âˆšâ†’\\sqrt, â‰¤â†’\\leq, â‰¥â†’\\geq, ğ‘¥áµ¢â†’x_i, ğ‘¥Â²â†’x^2

**è¡¨æ ¼å¤„ç†ï¼ˆæé‡è¦ï¼‰ï¼š**
- PDFæå–çš„è¡¨æ ¼å¯èƒ½ç”¨ [TABLE_START]...[TABLE_END] æ ‡è®°ï¼Œæ¯ä¸ªå•å…ƒæ ¼ç”¨ [TABLE_CELL: xxx] è¡¨ç¤º
- ä¾‹å¦‚ï¼š
  [TABLE_START]
  [TABLE_CELL: æ•°æ®é›†]
  [TABLE_CELL: ç±»åˆ«æ•°]
  [TABLE_CELL: CIFAR-10]
  [TABLE_CELL: 10]
  [TABLE_END]
- éœ€è¦æ ¹æ®è¡¨å¤´æ•°é‡ç¡®å®šåˆ—æ•°ï¼Œç„¶åå°†å•å…ƒæ ¼é‡ç»„ä¸ºè¡¨æ ¼è¡Œ
- **Markdownè¡¨æ ¼å¿…é¡»è½¬æ¢**ï¼šå¦‚æœçœ‹åˆ° | col1 | col2 | è¿™æ ·çš„ç®¡é“ç¬¦åˆ†éš”æ ¼å¼ï¼Œå¿…é¡»è½¬æ¢ä¸ºLaTeX
- **å¿…é¡»å°†æ‰€æœ‰è¡¨æ ¼è½¬æ¢ä¸ºLaTeX tabularæ ¼å¼**ï¼š
\\begin{table}[H]
\\centering
\\caption{æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­çš„è¡¨æ ¼æ ‡é¢˜}
\\begin{tabular}{|c|c|c|c|}
\\hline
åˆ—1 & åˆ—2 & åˆ—3 & åˆ—4 \\\\\\\\
\\hline
æ•°æ®1 & æ•°æ®2 & æ•°æ®3 & æ•°æ®4 \\\\\\\\
\\hline
\\end{tabular}
\\end{table}
- **ç¦æ­¢è¾“å‡º Markdown æ ¼å¼çš„è¡¨æ ¼**ï¼ˆå¦‚ | A | B | æˆ– |---|---| åˆ†éš”çº¿ï¼‰ï¼Œå¿…é¡»ç”¨ LaTeX tabular
- æ ¹æ®å†…å®¹æ¨æ–­åˆ—æ•°ï¼šå¦‚æœè¡¨å¤´æ˜¯"æ•°æ®é›†ã€ç±»åˆ«æ•°ã€è®­ç»ƒé›†ã€æµ‹è¯•é›†"åˆ™ä¸º4åˆ—
- **é‡è¦**ï¼šå¦‚æœæ— æ³•æ­£ç¡®è½¬æ¢è¡¨æ ¼ï¼Œè¯·ä¿ç•™åŸå§‹çš„ [TABLE_START]...[TABLE_END] å’Œ [TABLE_CELL:] æ ‡è®°ï¼Œä¸è¦åˆ é™¤å®ƒä»¬
${figureInstructions}
å†…å®¹ç‰‡æ®µï¼š
${contentToProcess}`;
}

/**
 * Parse the LLM response for a chunk
 */
export function parseChunkResponse(responseText: string, chunkIndex: number): Partial<ThesisData> {
  const parsed = JSON.parse(responseText);

  const result: Partial<ThesisData> = {};

  // Parse metadata (only from first chunk typically)
  if (parsed.metadata && Object.keys(parsed.metadata).length > 0) {
    result.metadata = {
      title: parsed.metadata.title?.trim() || '',
      title_en: parsed.metadata.title_en?.trim() || undefined,
      author_name: parsed.metadata.author_name?.trim() || '',
      student_id: parsed.metadata.student_id?.trim() || undefined,
      school: parsed.metadata.school?.trim() || undefined,
      major: parsed.metadata.major?.trim() || undefined,
      supervisor: parsed.metadata.supervisor?.trim() || undefined,
      date: parsed.metadata.date?.trim() || undefined,
    };
  }

  // Parse sections
  if (Array.isArray(parsed.sections)) {
    result.sections = [];
    for (const sec of parsed.sections) {
      if (sec.title || sec.content) {
        // Post-process content to convert any remaining markdown tables
        const processedContent = postProcessSectionContent(sec.content?.trim() || '');
        result.sections.push({
          title: sec.title?.trim() || '',
          content: processedContent,
          level: [1, 2, 3].includes(sec.level) ? sec.level : 1,
        });
      }
    }
  }

  // Parse special sections
  if (parsed.abstract?.trim()) {
    result.abstract = parsed.abstract.trim();
  }
  if (parsed.abstract_en?.trim()) {
    result.abstract_en = parsed.abstract_en.trim();
  }
  if (parsed.keywords?.trim()) {
    result.keywords = parsed.keywords.trim();
  }
  if (parsed.keywords_en?.trim()) {
    result.keywords_en = parsed.keywords_en.trim();
  }
  if (parsed.references?.trim()) {
    result.references = parsed.references.trim();
  }
  if (parsed.acknowledgements?.trim()) {
    result.acknowledgements = parsed.acknowledgements.trim();
  }

  return result;
}

/**
 * Convert markdown tables to LaTeX tabular format
 * This is a fallback in case the LLM doesn't convert them
 */
export function convertMarkdownTablesToLatex(content: string): string {
  // Match markdown table pattern: | col1 | col2 | ... followed by |---|---| separator
  const tableRegex = /(\|[^\n]+\|\n)(\|[-:\s|]+\|\n)((?:\|[^\n]+\|\n?)+)/g;

  return content.replace(tableRegex, (match, headerRow, separatorRow, bodyRows) => {
    try {
      // Parse header
      const headers = headerRow.split('|').filter((h: string) => h.trim()).map((h: string) => h.trim());
      const numCols = headers.length;

      if (numCols === 0) return match;

      // Parse body rows
      const rows: string[][] = [];
      const bodyLines = bodyRows.trim().split('\n');
      for (const line of bodyLines) {
        const cells = line.split('|').filter((c: string) => c.trim() !== '' || c === '').slice(0, -1);
        // Skip empty lines
        if (cells.length > 0 && cells.some((c: string) => c.trim())) {
          // Pad or trim to match header columns
          const row = cells.slice(cells[0] === '' ? 1 : 0).map((c: string) => c.trim());
          if (row.length > 0) {
            rows.push(row);
          }
        }
      }

      // Build LaTeX table
      const colSpec = '|' + 'c|'.repeat(numCols);
      let latex = '\\begin{table}[H]\n\\centering\n';
      latex += `\\begin{tabular}{${colSpec}}\n\\hline\n`;
      latex += headers.join(' & ') + ' \\\\\\\\ \\hline\n';
      for (const row of rows) {
        // Ensure row has correct number of columns
        while (row.length < numCols) row.push('');
        latex += row.slice(0, numCols).join(' & ') + ' \\\\\\\\ \\hline\n';
      }
      latex += '\\end{tabular}\n\\end{table}';

      return latex;
    } catch (e) {
      logger.warn(`Failed to convert markdown table: ${e}`);
      return match;
    }
  });
}

/**
 * Convert [TABLE_CELL:] format from PDF extraction to LaTeX
 */
export function convertTableCellsToLatex(content: string): string {
  // Match [TABLE_START]...[TABLE_END] blocks
  const tableBlockRegex = /\[TABLE_START\]\n([\s\S]*?)\[TABLE_END\]/g;

  return content.replace(tableBlockRegex, (match, cellsContent) => {
    try {
      // Extract all cells
      const cellRegex = /\[TABLE_CELL:\s*([^\]]+)\]/g;
      const cells: string[] = [];
      let cellMatch;
      while ((cellMatch = cellRegex.exec(cellsContent)) !== null) {
        cells.push(cellMatch[1].trim());
      }

      if (cells.length < 4) return match; // Not enough cells for a table

      // Try to determine number of columns by analyzing content
      // Heuristic: headers are usually short Chinese text, data rows start with alphanumeric identifiers
      let numCols = 4; // Default assumption

      // Count consecutive Chinese-only text cells at the start (likely headers)
      let headerCount = 0;
      for (const cell of cells) {
        // Check if cell is Chinese text (header candidate)
        if (/^[\u4e00-\u9fa5]+$/.test(cell)) {
          headerCount++;
          if (headerCount > 6) break;
        } else {
          // Found non-Chinese cell (data row starts)
          break;
        }
      }

      // If we found 2-6 Chinese headers, use that as column count
      if (headerCount >= 2 && headerCount <= 6) {
        numCols = headerCount;
      } else {
        // Fallback: try to detect repeating patterns
        // Look for the first numeric value and count cells before next occurrence of similar pattern
        const numericPattern = /^[\d,.\-+%]+$/;
        for (let i = 0; i < Math.min(10, cells.length); i++) {
          if (numericPattern.test(cells[i])) {
            // Found first number, look for next occurrence of number after non-numbers
            for (let j = i + 1; j < Math.min(i + 8, cells.length); j++) {
              if (numericPattern.test(cells[j]) && j - i >= 2 && j - i <= 6) {
                numCols = j - i + 1; // Include the number in the count
                break;
              }
            }
            break;
          }
        }
      }

      // Group cells into rows
      const rows: string[][] = [];
      for (let i = 0; i < cells.length; i += numCols) {
        const row = cells.slice(i, i + numCols);
        if (row.length === numCols) {
          rows.push(row);
        }
      }

      if (rows.length < 2) return match; // Need at least header + 1 data row

      // Build LaTeX table
      const colSpec = '|' + 'c|'.repeat(numCols);
      let latex = '\\begin{table}[H]\n\\centering\n';
      latex += `\\begin{tabular}{${colSpec}}\n\\hline\n`;

      // Header row
      latex += rows[0].join(' & ') + ' \\\\\\\\ \\hline\n';

      // Data rows
      for (let i = 1; i < rows.length; i++) {
        latex += rows[i].join(' & ') + ' \\\\\\\\ \\hline\n';
      }

      latex += '\\end{tabular}\n\\end{table}';
      return latex;
    } catch (e) {
      logger.warn(`Failed to convert TABLE_CELL format: ${e}`);
      return match;
    }
  });
}

/**
 * Unicode math character mappings to LaTeX
 */
const UNICODE_TO_LATEX: Record<string, string> = {
  // Greek letters (italic)
  'ğ›¼': '\\alpha', 'ğ›½': '\\beta', 'ğ›¾': '\\gamma', 'ğ›¿': '\\delta',
  'ğœ€': '\\epsilon', 'ğœ': '\\zeta', 'ğœ‚': '\\eta', 'ğœƒ': '\\theta',
  'ğœ„': '\\iota', 'ğœ…': '\\kappa', 'ğœ†': '\\lambda', 'ğœ‡': '\\mu',
  'ğœˆ': '\\nu', 'ğœ‰': '\\xi', 'ğœŠ': 'o', 'ğœ‹': '\\pi',
  'ğœŒ': '\\rho', 'ğœ': '\\sigma', 'ğœ': '\\tau', 'ğœ': '\\upsilon',
  'ğœ‘': '\\phi', 'ğœ’': '\\chi', 'ğœ“': '\\psi', 'ğœ”': '\\omega',
  // Greek letters (uppercase)
  'ğ›¢': 'A', 'ğ›£': 'B', 'ğ›¤': '\\Gamma', 'ğ›¥': '\\Delta',
  'ğ›¦': 'E', 'ğ›§': 'Z', 'ğ›¨': 'H', 'ğ›©': '\\Theta',
  'ğ›ª': 'I', 'ğ›«': 'K', 'ğ›¬': '\\Lambda', 'ğ›­': 'M',
  'ğ›®': 'N', 'ğ›¯': '\\Xi', 'ğ›°': 'O', 'ğ›±': '\\Pi',
  'ğ›²': 'P', 'ğ›³': '\\Sigma', 'ğ›´': '\\Sigma', 'ğ›µ': 'T',
  'ğ›¶': '\\Upsilon', 'ğ›·': '\\Phi', 'ğ›¸': 'X', 'ğ›¹': '\\Psi', 'ğ›º': '\\Omega',
  // Math italic letters
  'ğ‘': 'a', 'ğ‘': 'b', 'ğ‘': 'c', 'ğ‘‘': 'd', 'ğ‘’': 'e', 'ğ‘“': 'f',
  'ğ‘”': 'g', 'â„': 'h', 'ğ‘–': 'i', 'ğ‘—': 'j', 'ğ‘˜': 'k', 'ğ‘™': 'l',
  'ğ‘š': 'm', 'ğ‘›': 'n', 'ğ‘œ': 'o', 'ğ‘': 'p', 'ğ‘': 'q', 'ğ‘Ÿ': 'r',
  'ğ‘ ': 's', 'ğ‘¡': 't', 'ğ‘¢': 'u', 'ğ‘£': 'v', 'ğ‘¤': 'w', 'ğ‘¥': 'x',
  'ğ‘¦': 'y', 'ğ‘§': 'z',
  'ğ´': 'A', 'ğµ': 'B', 'ğ¶': 'C', 'ğ·': 'D', 'ğ¸': 'E', 'ğ¹': 'F',
  'ğº': 'G', 'ğ»': 'H', 'ğ¼': 'I', 'ğ½': 'J', 'ğ¾': 'K', 'ğ¿': 'L',
  'ğ‘€': 'M', 'ğ‘': 'N', 'ğ‘‚': 'O', 'ğ‘ƒ': 'P', 'ğ‘„': 'Q', 'ğ‘…': 'R',
  'ğ‘†': 'S', 'ğ‘‡': 'T', 'ğ‘ˆ': 'U', 'ğ‘‰': 'V', 'ğ‘Š': 'W', 'ğ‘‹': 'X',
  'ğ‘Œ': 'Y', 'ğ‘': 'Z',
  // Math operators and symbols
  'âˆ‘': '\\sum', 'âˆ': '\\prod', 'âˆ«': '\\int', 'âˆ¬': '\\iint', 'âˆ­': '\\iiint',
  'âˆ®': '\\oint', 'âˆ‡': '\\nabla', 'âˆ‚': '\\partial', 'âˆ†': '\\Delta',
  'âˆ€': '\\forall', 'âˆƒ': '\\exists', 'âˆˆ': '\\in', 'âˆ‰': '\\notin',
  'âŠ‚': '\\subset', 'âŠƒ': '\\supset', 'âŠ†': '\\subseteq', 'âŠ‡': '\\supseteq',
  'âˆª': '\\cup', 'âˆ©': '\\cap', 'âˆ§': '\\wedge', 'âˆ¨': '\\vee', 'Â¬': '\\neg',
  'âŠ•': '\\oplus', 'âŠ—': '\\otimes', 'âŠ™': '\\odot',
  'â‰¤': '\\leq', 'â‰¥': '\\geq', 'â‰ ': '\\neq', 'â‰ˆ': '\\approx',
  'â‰¡': '\\equiv', 'â‰¢': '\\not\\equiv', 'âˆ': '\\propto', 'âˆ': '\\infty',
  'Â±': '\\pm', 'Ã—': '\\times', 'Ã·': '\\div', 'âˆš': '\\sqrt',
  'âˆ›': '\\sqrt[3]', 'âˆœ': '\\sqrt[4]',
  'â†’': '\\rightarrow', 'â†': '\\leftarrow', 'â†”': '\\leftrightarrow',
  'â‡’': '\\Rightarrow', 'â‡': '\\Leftarrow', 'â‡”': '\\Leftrightarrow',
  // Superscripts
  'â°': '^{0}', 'Â¹': '^{1}', 'Â²': '^{2}', 'Â³': '^{3}', 'â´': '^{4}',
  'âµ': '^{5}', 'â¶': '^{6}', 'â·': '^{7}', 'â¸': '^{8}', 'â¹': '^{9}',
  'âº': '^{+}', 'â»': '^{-}', 'â¼': '^{=}', 'â½': '^{(}', 'â¾': '^{)}',
  'â¿': '^{n}', 'â±': '^{i}',
  // Subscripts
  'â‚€': '_{0}', 'â‚': '_{1}', 'â‚‚': '_{2}', 'â‚ƒ': '_{3}', 'â‚„': '_{4}',
  'â‚…': '_{5}', 'â‚†': '_{6}', 'â‚‡': '_{7}', 'â‚ˆ': '_{8}', 'â‚‰': '_{9}',
  'â‚Š': '_{+}', 'â‚‹': '_{-}', 'â‚Œ': '_{=}', 'â‚': '_{(}', 'â‚': '_{)}',
  'â‚': '_{a}', 'â‚‘': '_{e}', 'â‚’': '_{o}', 'â‚“': '_{x}',
  'â‚•': '_{h}', 'â‚–': '_{k}', 'â‚—': '_{l}', 'â‚˜': '_{m}',
  'â‚™': '_{n}', 'â‚š': '_{p}', 'â‚›': '_{s}', 'â‚œ': '_{t}',
  'áµ¢': '_{i}', 'â±¼': '_{j}',
};

/**
 * Check if a character is a Unicode math character
 */
function isUnicodeMathChar(char: string): boolean {
  return UNICODE_TO_LATEX.hasOwnProperty(char);
}

/**
 * Convert a formula block to LaTeX
 * Handles patterns like "N âˆ‘ L= âˆ’ i=1 yilog(pi)"
 */
function convertFormulaBlockToLatex(content: string): string {
  // First convert all Unicode chars
  let formula = content;
  for (const [unicode, latex] of Object.entries(UNICODE_TO_LATEX)) {
    formula = formula.split(unicode).join(latex);
  }

  // Try to detect and reconstruct common formula patterns

  // Pattern 1: Sum formula "N âˆ‘ L= âˆ’ i=1 body"
  // Matches: upper_limit sum_symbol lhs=- lower_limit body
  const sumPattern = /([NMKnmk])\s*\\sum\s*([A-Za-z])\s*=\s*[-âˆ’]?\s*([ijk])=(\d+)\s*(.+)/;
  const sumMatch = formula.match(sumPattern);
  if (sumMatch) {
    const [_, upper, lhs, idx, start, body] = sumMatch;
    return `$$${lhs} = -\\sum_{${idx}=${start}}^{${upper}} ${body}$$`;
  }

  // Pattern 2: Product formula
  const prodPattern = /([NMKnmk])\s*\\prod\s*([A-Za-z])\s*=\s*([ijk])=(\d+)\s*(.+)/;
  const prodMatch = formula.match(prodPattern);
  if (prodMatch) {
    const [_, upper, lhs, idx, start, body] = prodMatch;
    return `$$${lhs} = \\prod_{${idx}=${start}}^{${upper}} ${body}$$`;
  }

  // Pattern 3: Simple equation with operators
  if (/[A-Za-z]\s*=\s*[-+]?.*\\(?:sum|prod|int|frac)/.test(formula)) {
    return `$$${formula}$$`;
  }

  // If no pattern matched, wrap inline if it has LaTeX commands
  if (/\\(?:sum|prod|int|frac|alpha|beta|gamma)/.test(formula)) {
    return `$$${formula}$$`;
  }

  // Otherwise, make inline math
  if (formula.includes('=') || /[_^]/.test(formula)) {
    return `$${formula}$`;
  }

  return formula;
}

/**
 * Convert Unicode math characters to LaTeX
 */
export function convertUnicodeMathToLatex(content: string): string {
  let result = content;

  // Handle [FORMULA_BLOCK: ... :END_FORMULA_BLOCK] markers (multi-line formulas)
  result = result.replace(/\[FORMULA_BLOCK:\s*([\s\S]*?)\s*:END_FORMULA_BLOCK\]/g, (match, formulaContent) => {
    return convertFormulaBlockToLatex(formulaContent);
  });

  // Handle [FORMULA: ... :END_FORMULA] markers (single-line formulas)
  result = result.replace(/\[FORMULA:\s*([\s\S]*?)\s*:END_FORMULA\]/g, (match, formulaContent) => {
    // Convert Unicode characters first
    let converted = formulaContent;
    for (const [unicode, latex] of Object.entries(UNICODE_TO_LATEX)) {
      converted = converted.split(unicode).join(latex);
    }

    // Check if it looks like an equation
    if (converted.includes('=') || /\\(?:sum|prod|int|frac)/.test(converted)) {
      return `$${converted}$`;
    }
    return converted;
  });

  // Convert remaining Unicode math characters
  for (const [unicode, latex] of Object.entries(UNICODE_TO_LATEX)) {
    result = result.split(unicode).join(latex);
  }

  // Fix common patterns that result from PDF extraction
  // Pattern: "L = -\sum_{i=1}^{N}" should be wrapped in $$ if it's a standalone formula
  result = result.replace(/^(\s*)(\\?[A-Za-z]+\s*=\s*[-+]?\\(?:sum|prod|int|frac)[^$\n]+)(\s*)$/gm, (match, pre, formula, post) => {
    // Check if it looks like a display formula (has sum/prod/int)
    if (/\\(?:sum|prod|int|frac)/.test(formula)) {
      return `${pre}$$${formula.trim()}$$${post}`;
    }
    return match;
  });

  // Wrap inline math that has LaTeX commands but no delimiters
  result = result.replace(/(?<![$\\])\\(alpha|beta|gamma|delta|sum|prod|int|frac|sqrt)(?![a-zA-Z])/g, (match) => {
    return `$${match}$`;
  });

  // Fix subscripts/superscripts that are not in math mode
  result = result.replace(/(?<!\$)([a-zA-Z])_\{([^}]+)\}(?!\$)/g, '$$$1_{$2}$$');
  result = result.replace(/(?<!\$)([a-zA-Z])\^\{([^}]+)\}(?!\$)/g, '$$$1^{$2}$$');

  // Clean up adjacent inline math - merge $a$$b$ into $ab$
  result = result.replace(/\$\$\$/g, '$ $');
  result = result.replace(/\$\s*\$/g, '');

  // Fix mixed math delimiters - remove $ inside \[...\] or $$...$$
  result = result.replace(/\\\[\s*\$([^$]+)\$\s*\\\]/g, '\\[$1\\]');
  result = result.replace(/\$\$\s*\$([^$]+)\$\s*\$\$/g, '$$$1$$');

  // Fix \sum, \prod, etc. that have extra $ wrapping
  result = result.replace(/\$\\(sum|prod|int|frac|log)\$/g, '\\$1');

  return result;
}

/**
 * Reconstruct fragmented formulas from PDF extraction
 * PDF often splits formulas across multiple lines
 */
export function reconstructFormulas(content: string): string {
  let result = content;

  // Pattern 1: Sum formula split across lines
  // ğ‘ (or N)
  // âˆ‘ (or âˆ)
  // ğ¿= âˆ’ (or L= -)
  // ğ‘–=1 (or i=1)
  // ğ‘¦ğ‘–log(ğ‘ğ‘–)
  // Using specific character matches instead of ranges

  // Match upper limit characters
  const upperChars = '[ğ‘ğ‘€ğ¾ğ‘›ğ‘šğ‘˜NMKnmk]';
  // Match LHS variable characters
  const lhsChars = '[ğ¿ğ‘…ğ¸ğ½ğ‘ƒğ‘„LREJPQa-z]';
  // Match index characters
  const indexChars = '[ğ‘–ğ‘—ğ‘˜ijk]';

  const sumFormulaPattern = new RegExp(
    `(${upperChars})\\s*\\n\\s*[âˆ‘âˆ]\\s*\\n\\s*(${lhsChars}=\\s*[-âˆ’]?)\\s*\\n\\s*(${indexChars}=\\d+)\\s*\\n\\s*([^\\n]+)`,
    'g'
  );

  result = result.replace(sumFormulaPattern, (match, upper, lhs, lower, body) => {
    // Convert to proper LaTeX using the mapping
    let upperClean = upper;
    let lhsClean = lhs;
    let lowerClean = lower;

    // Apply Unicode to LaTeX conversions
    for (const [unicode, latex] of Object.entries(UNICODE_TO_LATEX)) {
      upperClean = upperClean.split(unicode).join(latex);
      lhsClean = lhsClean.split(unicode).join(latex);
      lowerClean = lowerClean.split(unicode).join(latex);
    }

    return `$$${lhsClean}\\sum_{${lowerClean}}^{${upperClean}} ${body}$$`;
  });

  return result;
}

/**
 * Post-process section content to fix common issues
 */
export function postProcessSectionContent(content: string): string {
  // First, try to reconstruct fragmented formulas
  let result = reconstructFormulas(content);
  // Convert Unicode math to LaTeX
  result = convertUnicodeMathToLatex(result);
  // Convert [TABLE_CELL:] format from PDF extraction
  result = convertTableCellsToLatex(result);
  // Convert any remaining markdown tables to LaTeX
  result = convertMarkdownTablesToLatex(result);
  return result;
}

/**
 * Delay helper for retry logic
 */
export function delay(ms: number): Promise<void> {
  return new Promise((resolve) => setTimeout(resolve, ms));
}

/**
 * Retry configuration
 */
export const RETRY_CONFIG = {
  maxRetries: 3,
  baseDelayMs: 2000,
  maxDelayMs: 10000,
};

/**
 * Calculate delay with exponential backoff
 */
export function calculateRetryDelay(retryCount: number): number {
  const delay = RETRY_CONFIG.baseDelayMs * Math.pow(2, retryCount);
  return Math.min(delay, RETRY_CONFIG.maxDelayMs);
}
